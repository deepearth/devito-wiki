# Frequently Asked Questions

- [How can I see the code generated by Devito](#how-can-i-see-the-code-generated-by-devito)
- [How can I see the compilation command with which Devito compiles the generated code](#how-can-i-see-the-compilation-command-with-which-devito-compiles-the-generated-code)
- [Where does the generated code go and how do I look at it](#where-does-the-generated-code-go-and-how-do-i-look-at-it)
- [Can I change the directory where Devito stashes the generated code](#can-i-change-the-directory-where-devito-stashes-the-generated-code)
- [I create an Operator, look at the generated code, and the equations appear in a different order than I expected.](#i-create-an-operator-look-at-the-generated-code-and-the-equations-appear-in-a-different-order-than-i-expected)
- [What environment variables control how Devito works](#what-environment-variables-control-how-devito-works)
- [How do you run the unit tests from the command line](#how-do-you-run-the-unit-tests-from-the-command-line)
- [What is the difference between f() and f[] notation](#what-is-the-difference-between-f-and-f-notation)
- [What is the indexed notation](#what-is-the-indexed-notation)
- [Is there a flow chart](#is-there-a-flow-chart)
- [What's up with object.data](#whats-up-with-objectdata)
- [What are the keys to fast code](#what-are-the-keys-to-fast-code)
- [As time increases in the finite difference evolution, are wavefield arrays "swapped" as you might see in c/c++ code](#as-time-increases-in-the-finite-difference-evolution-are-wavefield-arrays-swapped-as-you-might-see-in-cc-code)
- [What units are typically used in Devito examples](#what-units-are-typically-used-in-devito-examples)
- [How can I change the compilation flags (for example, I want to change the optimization level from -O3 to -O0)](#how-can-i-change-the-compilation-flags-for-example-i-want-to-change-the-optimization-level-from--o3-to--o0)
- [Can I control the MPI domain decomposition](#can-i-control-the-mpi-domain-decomposition)
- [Can I manually modify the C code generated by Devito and test these modifications](#can-i-manually-modify-the-c-code-generated-by-devito-and-test-these-modifications)
- [Is there a way to get the performance of an Operator](#is-there-a-way-to-get-the-performance-of-an-operator)
- [How does devito compute the performance of an Operator](#how-does-devito-compute-the-performance-of-an-operator)
- [Is there is list of refereed papers related to the Devito project](#is-there-a-list-of-refereed-papers-related-to-the-devito-project)
- [How do I cite Devito](#how-do-i-cite-devito)


## How can I see the code generated by Devito
After you build an ```Operator``` implementing one or more equations, you can use ```print(op.ccode)``` to see the generated low level code. Example below.

```
import numpy as np
import devito
from devito import *
from devito.finite_differences import Derivative
grid = Grid(shape=(21,), extent=(1.0,), origin=(0.0,), dtype=np.float32)
x = grid.dimensions[0]
f = Function(name='f', grid=grid, space_order=8)
g = Function(name='g', grid=grid, space_order=8)
eq_dfdx = Eq(g, getattr(f, 'dx')(x+0.5*x.spacing))
op = Operator(eq_dfdx)
print(op)
```

[top](#Frequently-Asked-Questions)


## How can I see the compilation command with which Devito compiles the generated code
Set the environment variable `DEVITO_DEBUG_COMPILER=1`. When an Operator gets compiled, the used compilation command will be emitted to stdout. 

If nothing seems to change, it is possible that no compilation is happening under-the-hood as all kernels have already been compiled in a previous run. You will then have to clear up the Devito kernel cache. From the Devito root directory, run:
```
python scripts/clear_devito_cache.py
```

[top](#Frequently-Asked-Questions)


## Where does the generated code go and how do I look at it
Devito stores the generated code as well as the jit-compiled libraries in a temporary directory. By setting the environment variable `DEVITO_LOGGING=DEBUG`, Devito will show, amongst other things, the absolute path to the generated code.

[top](#Frequently-Asked-Questions)


## Can I change the directory where Devito stashes the generated code

Yes, just set the environment variable `TMPDIR` to your favorite location. 

[top](#Frequently-Asked-Questions)


## I create an Operator, look at the generated code, and the equations appear in a different order than I expected.

The Devito compiler computes a topological ordering of the input equations based on data dependency analysis. Heuristically, some equations might be moved around to improve performance (e.g., data locality). Therefore, the order of the equations in the generated code might be different than that used as input to the Operator.

[top](#Frequently-Asked-Questions)


## What environment variables control how Devito works

### How to get the list of Devito environment variables
You can get the list of environment variables with the following python code:
```
from devito import print_defaults
print_defaults()
```

### How to set Devito environment variables

These environment variables can either be set from the shell or programmatically. Note that when setting these variables programmatically, you need to use lower case, and the leading ```DEVITO``` is omitted. Values are case sensitive, meaning ```openmp``` is accepted and ```OPENMP``` will throw an error. Below are examples of setting these variables in the shell (**before** running python) and from python (**before** executing devito code).

| Method | Example |
|:---|:---|
| bourne shell | DEVITO_LANGUAGE="openmp" |
| c shell | setenv DEVITO_LANGUAGE "openmp" |
| programmatically | configuration['language'] = 'openmp' |


### Table of values for Devito environment variables

Note the default values are in **bold**. Links in the table take you to a section describing how the variables controls the behavior of Devito execution.

| Variable | Values |
|:---|:---|
| [DEVITO_ARCH](#DEVITO_ARCH) | **custom**, gnu, gcc, clang, pgcc, pgi, osx, intel, icpc, icc, intel-knl, knl, gcc-4.9, gcc-5, gcc-6, gcc-7, gcc-8, gcc-9 | 
| [DEVITO_PLATFORM](#DEVITO_PLATFORM) | **cpu64**, cpu64-dummy, intel64, snb, ivb, hsw, bdw, skx, klx, clx, knl, knl7210, arm, power8, power9, nvidiaX] | 
| [DEVITO_PROFILING](#DEVITO_PROFILING) | **basic**, advanced, advisor | 
| [DEVITO_BACKEND](#DEVITO_BACKEND) | **core**, void | 
| [DEVITO_DEVELOP](#DEVITO_DEVELOP) | **True**, False | 
| [DEVITO_OPT](#DEVITO_OPT) | noop, **advanced**, advanced-fsg, (noop, C), (noop, openmp), (noop, openacc), (advanced, C), (advanced, openmp), (advanced, openacc), (advanced-fsg, C), (advanced-fsg, openmp), (advanced-fsg, openacc)] | 
| [DEVITO_MPI](#DEVITO_MPI) | **0**, 1, basic, diag, overlap, overlap2, full | 
| [DEVITO_LANGUAGE](#DEVITO_LANGUAGE) | 0, 1, **C**, openmp, openacc (0==C, 1==openmp)| 
| [DEVITO_AUTOTUNING](#DEVITO_AUTOTUNING) | **off**, basic, aggressive, max, [off, preemptive], [off, destructive], [off, runtime], [basic, preemptive], [basic, destructive], [basic, runtime], [aggressive, preemptive], [aggressive, destructive], [aggressive, runtime], [max, preemptive], [max, destructive], [max, runtime] | 
| [DEVITO_LOGGING](#DEVITO_LOGGING) | DEBUG, PERF, **INFO**, WARNING, ERROR, CRITICAL | 
| [DEVITO_FIRST_TOUCH](#DEVITO_FIRST_TOUCH) | **0**, 1 | 
| [DEVITO_DEBUG_COMPILER](#DEVITO_DEBUG_COMPILER) | **0**, 1 | 
| [DEVITO_JIT_BACKDOOR](#DEVITO_JIT_BACKDOOR) | **0**, 1 | 
| [DEVITO_IGNORE_UNKNOWN_PARAMS](#DEVITO_IGNORE_UNKNOWN_PARAMS) | **0**, 1 | 

### Description of Devito environment variables

#### DEVITO_ARCH
blah

#### DEVITO_PLATFORM
blah

#### DEVITO_PROFILING
blah

#### DEVITO_BACKEND
blah

#### DEVITO_DEVELOP
blah

#### DEVITO_OPT
blah

#### DEVITO_MPI
blah

#### DEVITO_LANGUAGE
blah

#### DEVITO_AUTOTUNING
blah

#### DEVITO_LOGGING
blah

#### DEVITO_FIRST_TOUCH
blah

#### DEVITO_DEBUG_COMPILER
blah

#### DEVITO_JIT_BACKDOOR
blah

#### DEVITO_IGNORE_UNKNOWN_PARAMS
blah


[top](#Frequently-Asked-Questions)


## How do you run the unit tests from the command line
In addition to the [tutorials]( https://www.devitoproject.org/devito/tutorials.html), the unit tests provide an excellent way to see how the Devito API works with small self-contained examples. You can exercise individual unit tests with the following python code:
```
Py.test <test.py>
Py.test -vs <test.py>  [more detailed log]
```

[top](#Frequently-Asked-Questions)


## What is the difference between f() and f[] notation
Devito offers a functional language to express finite difference operators. This is introduced [here](https://github.com/devitocodes/devito/blob/master/examples/userapi/01_dsl.ipynb) and systematically used throughout our examples and tutorials. The language relies on what in jargon we call the "f() notation".

```
>>> from devito import Grid, Function
>>> grid = Grid(shape=(5, 6))
>>> f = Function(name='f', grid=grid, space_order=2)
>>> f.dx
Derivative(f(x, y), x)
>>> f.dx.evaluate
-f(x, y)/h_x + f(x + h_x, y)/h_x
```

Sometimes, one wishes to escape the constraints of the language. Instead of taking derivatives, other special operations are required. Or perhaps, a specific grid point needs to be accessed. In such a case, one could use the "f[] notation" or "indexed notation". Following on from the example above:

```
>>> x, y = grid.dimensions
>>> f[x + 1000, y]
f[x + 1000, y]
```

The indexed object can be used at will to construct `Eq`s, and they can be mixed up with objects stemming from the "f() notation".

```
>>> f.dx + f[x + 1000, y]
Derivative(f(x, y), x) + f[x + 1000, y]
```

However, while the "f() notation" is substantially safe -- the language is designed such that only legal stencil expressions are built -- the "f[] notation" is not, and one can easily end up creating operators performing out-of-bounds accesses. So use it judiciously!

[top](#Frequently-Asked-Questions)


## What is the indexed notation 

The indexed notation, or "f[] notation", is discussed [here](#What-is-the-difference-between-f()-and-f[]-notation)

[top](#Frequently-Asked-Questions)


## Is there a flow chart
**needs links**
1. Equation Lowering
    - Indexification
    - Substitutions
    - Domain alignment
    - Eq -> LoweredEq
2. Local Analysis
3. Clustering
4. Symbolic Optimization via Devito Symbolic Engine (DSE)
5. IET (Iteration/Expression Tree) Construction
6. IET Analysis
7. IET Optimization (DLE/YLE)
    - Loop optimization via Devito Loop Engine (DLE)
    - Loop Tiling / Cache Blocking
    - SIMD
    - OpenMP
    - MPI
8. Synthetic
9. JIT (Just In Time) Compilation

[top](#Frequently-Asked-Questions)


## What's up with object\.data
The `.data` property which is associated with objects such as `Constant`, `Function` and `SparseFunction` (along with their derivatives) represents the 'numerical' value of the 'data' associated with that particular object. For example, a `Constant` will have a single numerical value associated with it as shown in the following snippet
```
from devito import Constant

c = Constant(name='c')
c.data = 2.7

print(c.data)
```
```
2.7
```
Then, a `Function` defined on a `Grid` will have a data value associated with each of the grid points (as shown in the snippet below) and so forth.
```
import numpy as np
from devito import Grid, Function

grid = Grid(shape=(4, 4), extent=(1, 1))
f = Function(name='f', grid=grid)
f.data[:] = np.arange(16).reshape(grid.shape)

print(f.data)
```
```
[[ 0.  1.  2.  3.]
 [ 4.  5.  6.  7.]
 [ 8.  9. 10. 11.]
 [12. 13. 14. 15.]]
```

[top](#Frequently-Asked-Questions)


## What are the keys to fast code
The code generated by devito is designed to run fast on CPU, GPU and clusters thereof. Broadly outlined, some of the mechanics for generating fast code are:
### CPU
* Loop tiling (or "cache blocking")
* Loop fusion (to maximize data locality)
Loop fission (to maximize parallelism)
* Flop-reducing transformations (CSE, cross-stencil redundancies, factorization, hoisting)
* OpenMP threading
* OpenMP-based SIMD
* Alignment to promote SIMD vectorization
### GPU
* Longer pipelines, less travel to host (do more work on the GPU before communicating data between host and GPU)
### Clusters of CPUs/GPUs
* Computation/communication overlap with prodding of the asynchronous progress engine
* Avoidance of unnecessary halo exchanges
* Reshuffling of halo exchanges
* Threaded data packing/unpacking

[top](#Frequently-Asked-Questions)


## As time increases in the finite difference evolution, are wavefield arrays "swapped" as you might see in c/c++ code

In c/c++ code using two wavefield arrays for second order acoustics, you might see code like the following to “swap” the wavefield arrays at each time step:
```
    float *p_tmp = p_old;
    p_old = p_cur;
    p_cur = p_tmp;
```

Instead of swapping arrays, devito uses the modulus of a time index to map increasing temporal indices [0, 1, 2, 3, 4, 5, ...] into cyclic indices [0, 1, 2, 0, 1, 2, ...].

[top](#Frequently-Asked-Questions)


## What units are typically used in Devito examples

- Sampling rates: msec
- Frequency: KHz
- Velocity: km/sec

[top](#Frequently-Asked-Questions)


## How can I change the compilation flags (for example, I want to change the optimization level from -O3 to -O0)

There is currently no API to achieve this straightforwardly. However, there are three workarounds:

* hacky way: change the flags explicitly in the Devito source code. In Devito v4.0, you can do that [here](https://github.com/opesci/devito/blob/v4.0/devito/compiler.py#L146)
* via env vars: use a [CustomCompiler](https://github.com/opesci/devito/blob/v4.0/devito/compiler.py#L446) -- just leave the `DEVITO_ARCH` environment variable unset or set it to `'custom'`. Then, `export CFLAGS="..."` to tell Devito to use the exported flags in place of the default ones.
* programmatically: subclass one of the compiler classes and set `self.cflags` to whatever you need. Do not forget to add the subclass to the [compiler registry](https://github.com/opesci/devito/blob/v4.0/devito/compiler.py#L472). For example, you could do

```
from devito import configuration, compiler_registry
from devito.compiler import GNUCompiler

class MyOwnCompiler(GNUCompiler):
    def __init__(self, *args, **kwargs):
        super(MyOwnCompiler, self).__init__(*args, **kwargs)
        # <manipulate self.cflags here >


### Make sure Devito is aware of this new Compiler class
compiler_registry['mycompiler'] = MyOwnCompiler
configuration.add("compiler", "custom", list(compiler_registry), callback=lambda i: compiler_registry[i]())


### Then, what remains to be done is asking Devito to use MyOwnCompiler

configuration['compiler'] = 'mycompiler'
```

[top](#Frequently-Asked-Questions)


## Can I control the MPI domain decomposition

Until Devito v3.5 included, domain decomposition occurs along the fastest axis. As of later versions, domain decomposition occurs along the slowest axis, for performance reasons.  And yes, it is possible to control the domain decomposition in user code, but this is undocumented and currently there exists no clean API to do that. However, below we provide some guidelines on how one can implement this.

* Start taking a look at the `Distributor` class, which controls the domain decomposition. In Devito v3.5, you can find it [here](https://github.com/opesci/devito/blob/v3.5/devito/mpi/distributed.py#L160).
* Turn the free function `compute_dims` into a `Distributor` method.
* In your user code, inherit from `Distributor` and override `compute_dims` at will. This will impact how the domain is decomposed along each of the distributed axes. 
* Change `Grid` to accept a `Distributor`, instead of `comm` (an MPI communicator). In Devito v3.5, you can do it [here](https://github.com/opesci/devito/blob/v3.5/devito/types/grid.py#L100).
* In your user code, create a `Grid` passing in an instance of the sub-classed `Distributor`, that is you should have `grid = Grid(...., distributor=MyDistributor(...))`.

[top](#Frequently-Asked-Questions)


## Can I manually modify the C code generated by Devito and test these modifications

Yes, as of Devito v3.5 it is possible to modify the generated C code and run it inside Devito. First you need to get the C file generated for a given `Operator`. Run your code in `DEBUG` mode:
```
DEVITO_LOGGING=DEBUG python your_code.py
```
The generated code path will be shown as in the excerpt below:
```
CustomCompiler: compiled `/tmp/devito-jitcache-uid1000/ed41e9373af1bc129471b7ae45e1c3740b60a856.c` [0.29 s]
```
You can now open the C file, do the modifications you like, and save them. Finally, rerun the same program but this time with the _Devito JIT backdoor_ enabled:
```
DEVITO_JIT_BACKDOOR=1 python your_code.py
```
This will force Devito to recompile and link the modified C code.

[top](#Frequently-Asked-Questions)

## Is there a way to get the performance of an Operator

Yes, any logging level below or equal to ``PERF`` will do the trick. For example, if you run:
```
DEVITO_LOGGING=PERF python your_code.py
```
you will see that Devito emits lots of useful information concerning the performance of an Operator. The following is reported:

* the code generation, compilation, and execution times;
* for each section in the generated code, its execution time, operational intensity (OI), GFlops/s and GPoints/s performance;
* global GFlops/s and GPoints/s performance of the Operator (i.e., cumulative across all sections);
* in the case of an MPI run, per-rank GFlops/s and GPoints/s performance.

There is only one caveat concerning the GPoints/s performance. You shall see two different GPoints/s indicators: one named ``FD-GPts/s`` and the other just ``GPts/s``:

* the ``FD-GPts/s`` is the metric typically used in finite-difference codes. The points are the actual grid points -- so if the grid is an ``N**3`` cube, the number of timesteps is ``T``, and the Operator has run for ``S`` secs, then we have ``N**3*T/S FD-GPoints/s``.
* the ``GPts/s`` is instead cumulative over the number of ``TimeFunctions`` defined (and actually written-to) over the grid. 

For example, consider an Operator implementing a wave propagator that writes to two ``TimeFunctions``. Assume the cost of all other non-FD operations is negligible (injection, BCs, ...). Then the ``GPts/s`` performance will be approximately twice as much as the ``FD-GPts/s`` performance.

An excerpt of the performance profile emitted by Devito upon running an Operator is provided below. In this case, the Operator has two sections, ``section0`` and ``section1``, and ``section1`` consists of two consecutive 6D iteration spaces whose size is given between angle brackets. 

```
Global performance indicators
  * Achieved 0.02 FD-GPts/s
Local performance indicators
  * section0<136,136,136> with OI=0.16 computed in 0.10 s [0.14 GFlops/s]
  * section1<<341,16,16,14,14,136>,<341,16,16,8,8,130>> with OI=5.36 computed in 35.91 s [8.01 GFlops/s, 0.05 GPts/s]
```


[top](#Frequently-Asked-Questions)

## How does Devito compute the performance of an Operator

The section execution time is computed directly in the generated code through cheap timers. The cumulative Operator execution time is computed through Python-level timers and includes the overhead inherent in the processing of the arguments supplied to `op.apply(...)`. 

The floating-point operations are counted once all of the symbolic flop-reducing transformations have been performed during compilation. Devito uses an in-house estimate of cost, rather than SymPy's estimate, to take care of some low-level intricacies. For example, Devito's estimate ignores the cost of integer arithmetic used for offset indexing into multi-dimensional arrays. Examples of how the Devito estimator works are available [here](https://github.com/devitocodes/devito/blob/v4.1/tests/test_dse.py#L265).

To calculate the GFlops/s performance, Devito multiplies the floating-point operations calculated at compile time by the size of the iteration space, and it does that at the granularity of individual expressions. For example, consider the following snippet:

```
<section0 start>
for x = x_m to x_M
  for y = y_m to y_M
    u[x, y] = 2*v[x, y] + 1
    for z = z_m to z_M
       w[x, y, z] += 4*h[x, y, z] + 5 - f[x, y, z]
<section 0 end>
```

At compile time, Devito produces the following estimate: ``2*(x_M-x_m+1)*(y_M-y_m+1) + 4*(x_M-x_m+1)*(y_M-y_m+1)*(z_M-z_m+1) = 2*(x_M-x_m+1)*(y_M-y_m+1)*(1 + 2*(z_M-z_m+1))``. Upon `op.apply(...)`, the values of `x_M, x_m, ...` become known and are instantied. This gives the total number of operations performed in ``section0``, which is eventually divided by the section execution time to give the GFlops/s performance.

The produced GFlops/s has been checked against that reported by Intel Advisor in a number of problems and the results were extremely close, which gives confidence about the soundness of the Devito estimate. Clearly, when it gets to articles or presentations, we encourage the use of profilers such as Intel Advisor to back these numbers up. The metrics emitted by Devito are only intended to give an initial yet fairly realistic indication of the Operator performance.

Compiler ninjas may wonder about the counting of loop-invariant sub-expressions, which might produce an over-estimate of the actual performance. Thanks to aggressive code motion, the amount of innermost-loop-invariant sub-expressions in a Devito Operator is typically negligible, so the Devito estimate doesn't basically suffer from this issue, or at least not in a tangible way to the best of our knowledge.

[top](#Frequently-Asked-Questions)


## Is there a list of refereed papers related to the Devito project

Please see https://www.devitoproject.org/publications 

[top](#Frequently-Asked-Questions)


## How do I cite Devito

Please see https://www.devitoproject.org/citing

[top](#Frequently-Asked-Questions)
